{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import os.path\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from pprint import pprint\n",
    "import urllib.request\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "from tqdm import tnrange,tqdm_notebook as tqdm\n",
    "tqdm().pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reviews dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The get_datasets function retrieves and concatenates the inputted number of json files into a single csv file for further processing. The json files are derived from the original 22.36GB dataset by running a script(json-splitter.py) to split them into json files approximately 200MB in size. A subset of 5 files will be used for this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datasets(start, end_range=5):\n",
    "    i = start\n",
    "    for a in tnrange(end_range,desc='loop'):\n",
    "        url = \"/Users/jocelynpok/Downloads/books_review/Books_5_{}.json\".format(str(i))\n",
    "        print(url)\n",
    "        data = pd.read_json(url)\n",
    "        df = pd.DataFrame.from_dict(data)\n",
    "       \n",
    "        \n",
    "        if a > 0 :\n",
    "            prev_posts = pd.read_csv('./amazon_book_reviews.csv')\n",
    "            current_df = df\n",
    "            combined_posts = pd.concat([prev_posts,current_df], ignore_index=True)\n",
    "            combined_posts.to_csv('./amazon_book_reviews.csv', index = False)\n",
    "\n",
    "        else:\n",
    "            df.to_csv('./amazon_book_reviews.csv', index = False)\n",
    "            print('created book reviews csv')\n",
    "        i += 1\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](amazon_books_dataset.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_datasets(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Books meta-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = pd.read_csv('/Users/jocelynpok/Downloads/amazon_book_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "asin_list = combined['asin'].unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The get_meta function retrieves the associated book meta data records based on the unique asin values from the reviews dataset above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_meta(start, end_range=66):\n",
    "    i = start\n",
    "    for a in tnrange(end_range,desc='loop'):\n",
    "        url = \"/Users/jocelynpok/Downloads/books_meta/meta_Books_{}.json\".format(str(i))\n",
    "        print(url)\n",
    "        data = pd.read_json(url)\n",
    "        df = pd.DataFrame.from_dict(data)\n",
    "        df_new = df[df['asin'].isin(asin_list)]\n",
    "        if df_new.shape[0] == 0:\n",
    "            i += 1\n",
    "            continue\n",
    "        else:\n",
    "            if a > 0 and os.path.isfile(\"/Users/jocelynpok/Downloads/books_meta/amazon_book_meta.csv\"):\n",
    "                prev_posts = pd.read_csv('/Users/jocelynpok/Downloads/books_meta/amazon_book_meta.csv')\n",
    "                current_df = df_new\n",
    "                combined_posts = pd.concat([prev_posts,current_df], ignore_index=True)\n",
    "                combined_posts.to_csv('/Users/jocelynpok/Downloads/books_meta/amazon_book_meta.csv', index = False)\n",
    "\n",
    "            else:\n",
    "                df_new.to_csv('/Users/jocelynpok/Downloads/books_meta/amazon_book_meta.csv', index = False)\n",
    "                \n",
    "        i += 1\n",
    "        \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
