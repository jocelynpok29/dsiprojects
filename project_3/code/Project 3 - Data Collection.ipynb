{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import re\n",
    "import time\n",
    "import random\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the requests library, data is pulled via the Reddit's API. Reddit only provides 25 posts per request. In order to get 500 posts per subreddit, the process was iterated through 20 times- a buffer to cater for duplicate posts. A list of nested json dictionaries is obtained of which are saved in 2 separate csv files for EDA and modelling in a separate notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.reddit.com/r/keto.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "from tqdm import tnrange,tqdm_notebook as tqdm\n",
    "tqdm().pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jocelynpok/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: TqdmDeprecationWarning: Please use `tqdm.notebook.trange` instead of `tqdm.tnrange`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb04993047ef4700a01c09536af3f3de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='loop', max=20.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.reddit.com/r/keto.json\n",
      "4\n",
      "https://www.reddit.com/r/keto.json?after=t3_gj1ps1\n",
      "2\n",
      "https://www.reddit.com/r/keto.json?after=t3_gic4s0\n",
      "2\n",
      "https://www.reddit.com/r/keto.json?after=t3_gimmqs\n",
      "2\n",
      "https://www.reddit.com/r/keto.json?after=t3_gicedv\n",
      "3\n",
      "https://www.reddit.com/r/keto.json?after=t3_gi0r8p\n",
      "6\n",
      "https://www.reddit.com/r/keto.json?after=t3_ghi7ou\n",
      "6\n",
      "https://www.reddit.com/r/keto.json?after=t3_ghcw3k\n",
      "4\n",
      "https://www.reddit.com/r/keto.json?after=t3_ggxv49\n",
      "3\n",
      "https://www.reddit.com/r/keto.json?after=t3_ggs7zu\n",
      "2\n",
      "https://www.reddit.com/r/keto.json?after=t3_gge4la\n",
      "2\n",
      "https://www.reddit.com/r/keto.json?after=t3_gg40to\n",
      "2\n",
      "https://www.reddit.com/r/keto.json?after=t3_gfrjnb\n",
      "3\n",
      "https://www.reddit.com/r/keto.json?after=t3_gfm23h\n",
      "6\n",
      "https://www.reddit.com/r/keto.json?after=t3_gfazst\n",
      "5\n",
      "https://www.reddit.com/r/keto.json?after=t3_gexvbe\n",
      "6\n",
      "https://www.reddit.com/r/keto.json?after=t3_gerzvo\n",
      "6\n",
      "https://www.reddit.com/r/keto.json?after=t3_gdeblc\n",
      "5\n",
      "https://www.reddit.com/r/keto.json?after=t3_gdvu3o\n",
      "5\n",
      "https://www.reddit.com/r/keto.json?after=t3_gdncr4\n",
      "5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "posts = []\n",
    "after = None\n",
    "#options = '&t=all&limit=100'\n",
    "my_list = list(range(20))\n",
    "#for a in tqdm(my_list):\n",
    "for a in tnrange(20,desc='loop'):\n",
    "    if after == None:\n",
    "        current_url = url\n",
    "    else:\n",
    "        current_url = url + '?after=' + after \n",
    "    print(current_url)\n",
    "    res = requests.get(current_url, headers={'User-agent': 'Pony Inc 1.0'})\n",
    "\n",
    "    if res.status_code != 200:\n",
    "        print('Status error', res.status_code)\n",
    "        break\n",
    "\n",
    "    current_dict = res.json()\n",
    "    current_posts = [p['data'] for p in current_dict['data']['children']]\n",
    "    posts.extend(current_posts)\n",
    "    after = current_dict['data']['after']\n",
    "\n",
    "    # COMPLETE THE CODE!\n",
    "    if a > 0:\n",
    "        prev_posts = pd.read_csv('../datasets/keto.csv')\n",
    "        current_df = pd.DataFrame(posts)\n",
    "        combined_posts = pd.concat([prev_posts,current_df], ignore_index=True)\n",
    "        combined_posts.to_csv('../datasets/keto.csv', index = False)\n",
    "\n",
    "    else:\n",
    "        pd.DataFrame(posts).to_csv('../datasets/keto.csv', index = False)\n",
    "\n",
    "    # generate a random sleep duration to look more 'natural'\n",
    "    sleep_duration = random.randint(2,6)\n",
    "    print(sleep_duration)\n",
    "    time.sleep(sleep_duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5290"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keto_df = pd.read_csv('../datasets/keto.csv')\n",
    "keto_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.reddit.com/r/gainit.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jocelynpok/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: TqdmDeprecationWarning: Please use `tqdm.notebook.trange` instead of `tqdm.tnrange`\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64d1217b4fce4a1fbfd0c0a229073f5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='loop', max=20.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.reddit.com/r/gainit.json\n",
      "3\n",
      "https://www.reddit.com/r/gainit.json?after=t3_ghu04s\n",
      "2\n",
      "https://www.reddit.com/r/gainit.json?after=t3_gevnsq\n",
      "3\n",
      "https://www.reddit.com/r/gainit.json?after=t3_gdh8a1\n",
      "6\n",
      "https://www.reddit.com/r/gainit.json?after=t3_gca57e\n",
      "3\n",
      "https://www.reddit.com/r/gainit.json?after=t3_g7pbdn\n",
      "4\n",
      "https://www.reddit.com/r/gainit.json?after=t3_g63xtu\n",
      "2\n",
      "https://www.reddit.com/r/gainit.json?after=t3_g38a3c\n",
      "6\n",
      "https://www.reddit.com/r/gainit.json?after=t3_g1r03k\n",
      "2\n",
      "https://www.reddit.com/r/gainit.json?after=t3_fzp7c1\n",
      "5\n",
      "https://www.reddit.com/r/gainit.json?after=t3_fxel1s\n",
      "4\n",
      "https://www.reddit.com/r/gainit.json?after=t3_ful5x9\n",
      "4\n",
      "https://www.reddit.com/r/gainit.json?after=t3_frodeb\n",
      "5\n",
      "https://www.reddit.com/r/gainit.json?after=t3_fqo22i\n",
      "3\n",
      "https://www.reddit.com/r/gainit.json?after=t3_fozrp4\n",
      "3\n",
      "https://www.reddit.com/r/gainit.json?after=t3_fnx13j\n",
      "3\n",
      "https://www.reddit.com/r/gainit.json?after=t3_fmrsl5\n",
      "6\n",
      "https://www.reddit.com/r/gainit.json?after=t3_fjw9gn\n",
      "5\n",
      "https://www.reddit.com/r/gainit.json?after=t3_fikvgu\n",
      "5\n",
      "https://www.reddit.com/r/gainit.json?after=t3_fgzqt2\n",
      "6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "posts = []\n",
    "after = None\n",
    "#options = '&t=all&limit=100'\n",
    "my_list = list(range(20))\n",
    "for a in tnrange(20,desc='loop'):\n",
    "#for x in tqdm(my_list):\n",
    "#for a in range(20):\n",
    "    if after == None:\n",
    "        current_url = url\n",
    "    else:\n",
    "        current_url = url + '?after=' + after \n",
    "    print(current_url)\n",
    "    res = requests.get(current_url, headers={'User-agent': 'Pony Inc 1.0'})\n",
    "    \n",
    "    if res.status_code != 200:\n",
    "        print('Status error', res.status_code)\n",
    "        break\n",
    "    \n",
    "    current_dict = res.json()\n",
    "    current_posts = [p['data'] for p in current_dict['data']['children']]\n",
    "    posts.extend(current_posts)\n",
    "    after = current_dict['data']['after']\n",
    "    \n",
    "    # COMPLETE THE CODE!\n",
    "    if a > 0:\n",
    "        prev_posts = pd.read_csv('../datasets/gainit.csv')\n",
    "        current_df = pd.DataFrame(posts)\n",
    "        combined_posts = pd.concat([prev_posts,current_df], ignore_index=True)\n",
    "        combined_posts.to_csv('../datasets/gainit.csv', index = False)\n",
    "        \n",
    "    else:\n",
    "        pd.DataFrame(posts).to_csv('../datasets/gainit.csv', index = False)\n",
    "    \n",
    "    # generate a random sleep duration to look more 'natural'\n",
    "    sleep_duration = random.randint(2,6)\n",
    "    print(sleep_duration)\n",
    "    time.sleep(sleep_duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5290"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gainIt_df = pd.read_csv('../datasets/gainit.csv')\n",
    "gainIt_df.shape[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
